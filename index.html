<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>Scroll-Triggered Audio (Fully In View for All Tracks)</title>
  <style>
    html, body { margin:0; padding:0; }
    #startStop {
      position: fixed; top:10px; left:10px; z-index:100;
      padding:8px 12px; font-size:16px;
    }
    section {
      height:100vh;
      display:flex; justify-content:center; align-items:center;
      font-size:2rem;
    }
    section[data-track="rainAudio"]  { background:#e0f7fa; }
    section[data-track="pianoAudio"] { background:#ffe0b2; }
    section[data-track="kidsAudio"]  { background:#c8e6c9; }
  </style>
</head>
<body>
  <button id="startStop">Start Audio</button>

  <!-- Your audio files must be in the same folder -->
  <audio id="rainAudio"  src="rain.mp3"          preload="auto" loop></audio>
  <audio id="pianoAudio" src="piano.mp3"         preload="auto" loop></audio>
  <audio id="kidsAudio"  src="kids_playing.mp3"  preload="auto" loop></audio>

  <section data-track="rainAudio">Rain Sound</section>
  <section data-track="pianoAudio">Piano Sound</section>
  <section data-track="kidsAudio">Kids Playing</section>

  <script>
    let audioCtx = null;
    const tracks = {};  // will hold { el, gain, started }

    document.getElementById('startStop').addEventListener('click', () => {
      const btn = document.getElementById('startStop');

      if (!audioCtx) {
        // 1) Unlock AudioContext on user gesture
        audioCtx = new (window.AudioContext||window.webkitAudioContext)();
        btn.textContent = 'Stop Audio';

        // 2) For each <audio>, create a GainNode (start at 0), wire into AudioContext, and play
        document.querySelectorAll('audio').forEach(el => {
          const source = audioCtx.createMediaElementSource(el);
          const gain   = audioCtx.createGain();
          gain.gain.value = 0;                    // start completely silent
          source.connect(gain).connect(audioCtx.destination);
          tracks[el.id] = { el, gain, started: false };
          el.play();                              // user gesture unlocks playback
        });

        // 3) Observe each section; only fire when fully in view (threshold:1.0)
        const observer = new IntersectionObserver((entries) => {
          entries.forEach(entry => {
            if (entry.intersectionRatio === 1) {
              const id = entry.target.dataset.track;
              const t  = tracks[id];
              if (!t.started) {
                // fade gain from 0 â†’ 0.5 over 0.1s
                t.gain.gain.setTargetAtTime(0.5, audioCtx.currentTime, 0.1);
                t.started = true;
              }
            }
          });
        }, { threshold: 1.0 });

        document.querySelectorAll('section').forEach(sec => {
          observer.observe(sec);
        });

      } else {
        // Stop & reset everything
        Object.values(tracks).forEach(t => {
          t.el.pause();
          t.el.currentTime = 0;
        });
        audioCtx.close();
        audioCtx = null;
        btn.textContent = 'Start Audio';
      }
    });
  </script>
</body>
</html>
